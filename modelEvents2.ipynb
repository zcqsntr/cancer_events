{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim here is to train a supervised CNN to recognise duplications and deletions\n",
    "1) Generate some event data to classify\n",
    "2) Define the network\n",
    "3) Do some training \n",
    "4) Test the prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f645c0b9050>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "rng.seed(1001)\n",
    "torch.manual_seed(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "# 1) Generate some data\n",
    "\n",
    "def data_generator(ndat,nL,sd):\n",
    "    data = np.zeros((ndat,1,nL)) \n",
    "    labs = np.zeros((ndat,)) \n",
    "    for i in range(0,ndat):\n",
    "        # choose dup or del\n",
    "        evnt = rng.choice([-1,1])\n",
    "        #labs[i,] = int( (evnt+1)/2 )\n",
    "        if evnt == -1:\n",
    "            labs[i,] = 0\n",
    "        else:\n",
    "            labs[i,] = 1\n",
    "    \n",
    "        # choose start\n",
    "        start = rng.randint(0,nL-1)\n",
    "        #print(start,\"\\t\",type)\n",
    "        #start = 4\n",
    "    \n",
    "        # create event and add noise\n",
    "        data[i,0, start:(start+2)] = evnt\n",
    "        data[i,0,] += rng.normal(0,sd,(nL))\n",
    "    \n",
    "        #print(data[i,])\n",
    "\n",
    "    return [data, labs]\n",
    "        \n",
    "ndat = 10000\n",
    "nL = 10\n",
    "sd = 0.5\n",
    "data, labs = data_generator(ndat, nL, sd)\n",
    "x_train = torch.from_numpy(data).float()\n",
    "y_train = torch.from_numpy(labs).long()\n",
    "#print(labs)\n",
    "#print(data[0:5,])\n",
    "print(data.shape)\n",
    "\n",
    "ntest = 1000\n",
    "tdata, tlabs = data_generator(ntest, nL, sd)\n",
    "x_test = torch.from_numpy(tdata).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1645, 0.3557],\n",
      "        [0.1634, 0.3559],\n",
      "        [0.1617, 0.3567],\n",
      "        [0.1604, 0.3579],\n",
      "        [0.1635, 0.3562],\n",
      "        [0.1617, 0.3572],\n",
      "        [0.1627, 0.3568],\n",
      "        [0.1626, 0.3563],\n",
      "        [0.1655, 0.3548],\n",
      "        [0.1566, 0.3597]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 2) Define a model. We will add some convolution\n",
    "class Model1(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Model1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1, 1, 3)\n",
    "        self.linear = nn.Linear(6, n_class)\n",
    "        self.pool = nn.MaxPool1d(3, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        out = F.relu(self.conv1(x))\n",
    "        print(out.shape)\n",
    "        out = self.pool( out )\n",
    "        print(out.shape)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out[:,0,:]\n",
    "    \n",
    "class Model2(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Model2, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 2, 3)\n",
    "        self.conv2 = nn.Conv1d(2, 4, 3)\n",
    "        self.pool = nn.MaxPool1d(3, stride=1)\n",
    "        \n",
    "        self.layer1 = nn.Linear(16, 16)\n",
    "        self.layer2 = nn.Linear(16, 8)\n",
    "        self.final = nn.Linear(8, n_class)\n",
    "           \n",
    "        self.debug = 0\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.debug: print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        if self.debug: print(x.shape)\n",
    "        x = self.pool( x )\n",
    "        if self.debug: print(x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        if self.debug: print(x.shape)\n",
    "        \n",
    "        # flatten into vector\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        if self.debug: print(x.shape)\n",
    "        \n",
    "        x = F.relu(self.layer1(x))\n",
    "        if self.debug: print(x.shape)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        if self.debug: print(x.shape)\n",
    "        x = self.final(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "model = Model2(nL, 2)\n",
    "#print(model)\n",
    "print(model(x_train[0:10,]))\n",
    "#print(model(x_train[0:10,]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/100], loss: 0.705171\n",
      "Epoch[20/100], loss: 0.701657\n",
      "Epoch[30/100], loss: 0.699704\n",
      "Epoch[40/100], loss: 0.716571\n",
      "Epoch[50/100], loss: 0.701381\n",
      "Epoch[60/100], loss: 0.699444\n",
      "Epoch[70/100], loss: 0.701022\n",
      "Epoch[80/100], loss: 0.701324\n",
      "Epoch[90/100], loss: 0.701276\n",
      "Epoch[100/100], loss: 0.691762\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# 3) Do some training\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "num_epochs = int(ndat/batch_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "i = 0\n",
    "for epoch in range(num_epochs):\n",
    "    #inds = rng.choice(range(0,ndat),size=batch_size, replace=False)\n",
    "    inds = range(i,i+batch_size)\n",
    "    inputs = x_train[inds,]\n",
    "    target = y_train[inds,]\n",
    "    \n",
    "    i += batch_size\n",
    "    \n",
    "    # forward\n",
    "    out = model(inputs)\n",
    "    #print(target.shape)\n",
    "    #print(out.shape)\n",
    "    loss = criterion(out, target)\n",
    "    \n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch[{epoch+1}/{num_epochs}], loss: {loss.item():.6f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 48 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    outputs = model(x_test)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    #print( abs(predicted-labs) )\n",
    "    incorrect = (abs(predicted-tlabs)).sum()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * (ntest-incorrect) / float(ntest)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight tensor([[[-0.1207, -0.3933,  0.4114]],\n",
      "\n",
      "        [[-0.3890, -0.3564, -0.2458]]])\n",
      "conv1.bias tensor([-0.3308,  0.1718])\n",
      "conv2.weight tensor([[[ 0.3405, -0.2432, -0.3101],\n",
      "         [-0.0230, -0.1485,  0.1079]],\n",
      "\n",
      "        [[-0.2858, -0.0297, -0.3580],\n",
      "         [ 0.2312,  0.0792, -0.3772]],\n",
      "\n",
      "        [[ 0.0109, -0.2679,  0.0240],\n",
      "         [-0.0918,  0.3859, -0.2942]],\n",
      "\n",
      "        [[ 0.1890,  0.1190,  0.3511],\n",
      "         [-0.1699, -0.2201,  0.2542]]])\n",
      "conv2.bias tensor([-0.1205, -0.4043,  0.0718, -0.1497])\n",
      "layer1.weight tensor([[-0.0086, -0.0028, -0.1496,  0.0049,  0.0522,  0.2327, -0.1648,  0.1904,\n",
      "         -0.0986, -0.2262, -0.1955,  0.2381,  0.0747, -0.2116,  0.2221, -0.0166],\n",
      "        [-0.0950,  0.2329, -0.0409,  0.0801,  0.2103,  0.0507,  0.0474,  0.0977,\n",
      "         -0.2380,  0.2072,  0.0870, -0.1018,  0.0195,  0.0654,  0.2215,  0.1142],\n",
      "        [ 0.1180,  0.1390, -0.1215, -0.1335,  0.1848, -0.0397, -0.0632, -0.1476,\n",
      "          0.2065, -0.1633,  0.2112,  0.0899,  0.0642,  0.0933, -0.1613, -0.0566],\n",
      "        [ 0.0259,  0.0921, -0.2385,  0.2226, -0.0112,  0.1843, -0.1490, -0.1237,\n",
      "          0.1441,  0.1525,  0.1052, -0.1507,  0.0753,  0.0453,  0.0141, -0.0003],\n",
      "        [-0.0038, -0.2355,  0.1680,  0.2053,  0.2264,  0.1907, -0.1696,  0.0457,\n",
      "         -0.0766,  0.1453,  0.0567,  0.1039,  0.1288,  0.0631,  0.1789,  0.1476],\n",
      "        [-0.2214, -0.0825, -0.2470,  0.0342,  0.0481,  0.2463, -0.1027,  0.0929,\n",
      "          0.0726,  0.1301,  0.0235, -0.2175, -0.1611,  0.0243, -0.2098, -0.1111],\n",
      "        [-0.2047, -0.0611,  0.1983,  0.0574, -0.2401, -0.1964, -0.0720, -0.1951,\n",
      "          0.2196,  0.2424, -0.2195,  0.2317,  0.1985, -0.1337, -0.0038,  0.0996],\n",
      "        [ 0.0978, -0.1973, -0.1285, -0.0539, -0.1460, -0.0800, -0.0604,  0.2101,\n",
      "         -0.2385,  0.1270,  0.1576,  0.0326,  0.1704, -0.1364,  0.2302,  0.0118],\n",
      "        [-0.0610, -0.0804, -0.1876, -0.1883, -0.1325,  0.2365,  0.1886, -0.2475,\n",
      "          0.0166, -0.2238,  0.1290,  0.0305, -0.2404, -0.1941,  0.0328, -0.1262],\n",
      "        [ 0.1793, -0.0723,  0.1134, -0.0117, -0.0137,  0.0283,  0.1576,  0.1859,\n",
      "         -0.1678, -0.0071, -0.0057, -0.1188,  0.0888, -0.0865,  0.0301,  0.0372],\n",
      "        [-0.0641, -0.1802, -0.0889, -0.2320, -0.0246, -0.1590,  0.2337,  0.1262,\n",
      "          0.0190,  0.0310, -0.0020, -0.0877, -0.0821,  0.0589,  0.0827,  0.1442],\n",
      "        [-0.2029,  0.1924,  0.0137, -0.1840, -0.0932, -0.0750, -0.0053,  0.0079,\n",
      "          0.1484,  0.0312,  0.2035, -0.0822,  0.2413, -0.1430,  0.2248, -0.2417],\n",
      "        [ 0.1999,  0.1042,  0.1424, -0.1088, -0.0374,  0.0475,  0.0714,  0.0449,\n",
      "          0.0905,  0.0191, -0.1566,  0.1959,  0.0966,  0.1218, -0.0729,  0.0703],\n",
      "        [-0.1701,  0.1318, -0.0090, -0.2087, -0.1640, -0.1209, -0.2330, -0.0440,\n",
      "          0.1195,  0.0637, -0.1120,  0.1493,  0.1449, -0.0173,  0.1776, -0.0470],\n",
      "        [-0.0930,  0.0395, -0.1566, -0.2428, -0.2019,  0.2462, -0.0638, -0.0496,\n",
      "          0.0906, -0.1615,  0.0315,  0.0365,  0.1726,  0.0950,  0.1259, -0.0044],\n",
      "        [-0.0187, -0.1336,  0.0542, -0.0793, -0.1274, -0.1099,  0.0677, -0.1555,\n",
      "         -0.2301, -0.1412,  0.0118,  0.1987, -0.2333, -0.0807, -0.0045,  0.1471]])\n",
      "layer1.bias tensor([-0.2135,  0.1715,  0.0349, -0.1870,  0.0838, -0.2287, -0.2497,  0.1977,\n",
      "        -0.2363,  0.0227,  0.1295,  0.0532, -0.1416, -0.2110, -0.0493, -0.0201])\n",
      "layer2.weight tensor([[-0.0059,  0.1020, -0.0109, -0.1093,  0.1141,  0.0825, -0.1105,  0.2393,\n",
      "          0.1937,  0.0194,  0.2376, -0.1497,  0.1995,  0.0107,  0.0142,  0.1697],\n",
      "        [ 0.1301,  0.1534,  0.0853, -0.1084, -0.1940,  0.1315, -0.0327,  0.0626,\n",
      "         -0.0298, -0.2468, -0.0722,  0.1729, -0.0025, -0.2422, -0.2192, -0.1842],\n",
      "        [ 0.1434,  0.1356, -0.0851, -0.1458,  0.0595, -0.1895,  0.1746, -0.1945,\n",
      "          0.1733, -0.0512, -0.0528, -0.0823, -0.1645, -0.1541,  0.2335,  0.2028],\n",
      "        [-0.2418,  0.2481,  0.1914,  0.1241,  0.1212, -0.2412,  0.2365,  0.1365,\n",
      "         -0.1643, -0.1500,  0.1697, -0.1296, -0.0249, -0.1109, -0.2195,  0.1056],\n",
      "        [-0.1472,  0.0959, -0.1284, -0.0807, -0.1727,  0.0098,  0.1707, -0.1448,\n",
      "         -0.1235,  0.2051,  0.0224, -0.1740, -0.0390,  0.1714, -0.0243, -0.2413],\n",
      "        [-0.2415,  0.0258, -0.0454, -0.0717,  0.0180, -0.2125, -0.0505,  0.0100,\n",
      "         -0.2230,  0.0459,  0.1745, -0.1142, -0.2491, -0.0810,  0.0732, -0.1179],\n",
      "        [-0.1548,  0.0309,  0.0158, -0.2432,  0.2132,  0.2114, -0.1209, -0.1799,\n",
      "         -0.1375, -0.0291,  0.1741,  0.2220, -0.2157,  0.1321,  0.0148, -0.2251],\n",
      "        [ 0.1315, -0.2472,  0.0437, -0.2227, -0.1747,  0.0335, -0.0112,  0.0947,\n",
      "          0.1345, -0.1270,  0.1472, -0.1921, -0.1970, -0.0571,  0.1448, -0.0589]])\n",
      "layer2.bias tensor([-0.1237, -0.1018, -0.1630, -0.0892, -0.1079,  0.0961, -0.1339,  0.0055])\n",
      "final.weight tensor([[ 0.0166,  0.1697, -0.2778, -0.1171, -0.3286, -0.2916,  0.1100, -0.2709],\n",
      "        [ 0.1516,  0.0026, -0.2534,  0.1522, -0.3131,  0.0348, -0.0496, -0.2699]])\n",
      "final.bias tensor([0.2033, 0.3459])\n"
     ]
    }
   ],
   "source": [
    "# examine the parameters of the fitted model\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
